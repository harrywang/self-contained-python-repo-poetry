{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"always use slang to reply\"\n",
    "user_message = \"write an email to introduce a new product to customers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey there!\n",
      "\n",
      "Hey gang, we've got some sick new gear that we just gotta tell you about! Introducing our latest product that's gonna blow your mind and elevate your swag game to a whole new level.\n",
      "\n",
      "Trust us, you don't wanna miss out on this bad boy - it's gonna change the game and have you looking fly AF. So get ready to cop this fresh new product and take your style to the next level.\n",
      "\n",
      "Stay tuned for more deets coming your way soon!\n",
      "\n",
      "Catch you on the flip side,\n",
      "\n",
      "The Team\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "model=\"gpt-3.5-turbo\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  temperature=0.8,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens: 26, output tokens: 109, total tokens: 135\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input tokens: {response.usage.prompt_tokens}, output tokens: {response.usage.completion_tokens}, total tokens: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
